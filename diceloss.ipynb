{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5, 2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones([16,5,2,3])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(480., dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(a)\n",
    "torch.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.Tensor([[\n",
    "        [[0, 1, 0, 0],\n",
    "         [1, 0, 0, 1],\n",
    "         [1, 0, 0, 1],\n",
    "         [0, 1, 1, 0]],\n",
    "        [[0, 0, 0, 0],\n",
    "         [0, 0, 0, 0],\n",
    "         [0, 1, 1, 0],\n",
    "         [0, 0, 0, 0]],\n",
    "        [[1, 0, 1, 1],\n",
    "         [0, 1, 1, 0],\n",
    "         [0, 0, 0, 0],\n",
    "         [1, 0, 0, 1]]],\n",
    "        [\n",
    "            [[0, 1, 0, 0],\n",
    "             [1, 0, 0, 1],\n",
    "             [1, 0, 0, 1],\n",
    "             [0, 1, 1, 0]],\n",
    "            [[0, 0, 0, 0],\n",
    "             [0, 0, 0, 0],\n",
    "             [0, 1, 1, 0],\n",
    "             [0, 0, 0, 0]],\n",
    "            [[1, 0, 1, 1],\n",
    "             [0, 1, 1, 0],\n",
    "             [0, 0, 0, 0],\n",
    "             [1, 0, 0, 1]]]\n",
    "    ])\n",
    " \n",
    "gt = torch.Tensor([[\n",
    "        [[0, 1, 1, 0],\n",
    "         [1, 0, 0, 1],\n",
    "         [1, 0, 0, 1],\n",
    "         [0, 1, 1, 0]],\n",
    "        [[0, 0, 0, 0],\n",
    "         [0, 0, 0, 0],\n",
    "         [0, 1, 1, 0],\n",
    "         [0, 0, 0, 0]],\n",
    "        [[1, 0, 0, 1],\n",
    "         [0, 1, 1, 0],\n",
    "         [0, 0, 0, 0],\n",
    "         [1, 0, 0, 1]]],\n",
    "        [\n",
    "            [[0, 1, 1, 0],\n",
    "             [1, 0, 0, 1],\n",
    "             [1, 0, 0, 1],\n",
    "             [0, 1, 1, 0]],\n",
    "            [[0, 0, 0, 0],\n",
    "             [0, 0, 0, 0],\n",
    "             [0, 1, 1, 0],\n",
    "             [0, 0, 0, 0]],\n",
    "            [[1, 0, 0, 1],\n",
    "             [0, 1, 1, 0],\n",
    "             [0, 0, 0, 0],\n",
    "             [1, 0, 0, 1]]]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,0:1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 3. ],\n",
       "       [0.5, 1.5, 9. ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0,1,3],\n",
    "    [0.5,1.5,9]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.73105858, 0.95257413],\n",
       "       [0.62245933, 0.81757448, 0.99987661]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diceCoeff(pred, gt, smooth=1e-5, activation='sigmoid'):\n",
    "    r\"\"\" computational formula：\n",
    "        dice = (2 * (pred ∩ gt)) / (pred ∪ gt)\n",
    "    \"\"\"\n",
    " \n",
    "    if activation is None or activation == \"none\":\n",
    "        activation_fn = lambda x: x\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    elif activation == \"softmax2d\":\n",
    "        activation_fn = nn.Softmax2d()\n",
    "    else:\n",
    "        raise NotImplementedError(\"Activation implemented for sigmoid and softmax2d 激活函数的操作\")\n",
    " \n",
    "    pred = activation_fn(pred)\n",
    " \n",
    "    N = gt.size(0)\n",
    "    pred_flat = pred.view(N, -1)\n",
    "    gt_flat = gt.view(N, -1)\n",
    " \n",
    "    intersection = (pred_flat * gt_flat).sum(1)\n",
    "    unionset = pred_flat.sum(1) + gt_flat.sum(1)\n",
    "    loss = (2 * intersection + smooth) / (unionset + smooth)\n",
    " \n",
    "    return loss.sum() / N\n",
    " \n",
    " \n",
    " \n",
    "def diceCoeffv2(pred, gt, eps=1e-5, activation='sigmoid'):\n",
    "    r\"\"\" computational formula：\n",
    "        dice = (2 * tp) / (2 * tp + fp + fn)\n",
    "    \"\"\"\n",
    " \n",
    "    if activation is None or activation == \"none\":\n",
    "        activation_fn = lambda x: x\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    elif activation == \"softmax2d\":\n",
    "        activation_fn = nn.Softmax2d()\n",
    "    else:\n",
    "        raise NotImplementedError(\"Activation implemented for sigmoid and softmax2d 激活函数的操作\")\n",
    " \n",
    "    pred = activation_fn(pred)\n",
    " \n",
    "    N = gt.size(0)\n",
    "    pred_flat = pred.view(N, -1)\n",
    "    gt_flat = gt.view(N, -1)\n",
    " \n",
    "    tp = torch.sum(gt_flat * pred_flat, dim=1)\n",
    "    fp = torch.sum(pred_flat, dim=1) - tp\n",
    "    fn = torch.sum(gt_flat, dim=1) - tp\n",
    "    loss = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
    "    return loss.sum() / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLossV2(_Loss):\n",
    "    __name__ = 'dice_loss'\n",
    " \n",
    "    def __init__(self, num_classes, activation='sigmoid', reduction='mean'):\n",
    "        super(SoftDiceLossV2, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.num_classes = num_classes\n",
    " \n",
    "    def forward(self, y_pred, y_true):\n",
    "        class_dice = []\n",
    "        for i in range(1, self.num_classes):\n",
    "            class_dice.append(diceCoeff(y_pred[:, i:i + 1, :], y_true[:, i:i + 1, :], activation=self.activation))\n",
    "        mean_dice = sum(class_dice) / len(class_dice)\n",
    "        return 1 - mean_dice\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
